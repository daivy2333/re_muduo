非常好的问题！理解 **“为什么用这个而不是那个”** 是区分“会用 API”和“真正懂系统”的关键。下面我为你系统梳理 **Linux 网络编程中几组经典技术选型的对比与演进逻辑**，包括 `eventfd` vs `pipe`、`epoll` vs `select/poll`、`SO_REUSEADDR` vs `SO_REUSEPORT` 等，并给出简洁、准确、面试友好的回答。

---

## 一、`eventfd` vs `pipe`：为什么 `EventLoop` 用 `eventfd` 唤醒？

### ❓ 问题：  
> “`EventLoop` 需要被其他线程唤醒，为什么用 `eventfd` 而不用传统的 `pipe`？”

### ✅ 回答要点：
| 维度 | `pipe` | `eventfd` | 优势 |
|------|-------|----------|------|
| **资源消耗** | 占用两个 fd（读+写） | 只占一个 fd | 节省文件描述符（对高并发服务重要） |
| **数据语义** | 字节流（需写入/读取具体字节） | 计数器（8 字节整数，自动累加） | 无需关心内容，只关心“有事件” |
| **性能** | 内核需管理 pipe buffer | 无缓冲区，纯计数器 | 更少内存拷贝，更低延迟 |
| **可移植性** | POSIX 标准，跨平台 | Linux 特有（2.6.22+） | 在 Linux 服务器场景下是首选 |

### 🗣️ 面试口语化回答：
> “`eventfd` 是 Linux 专门为‘事件通知’设计的机制。相比 `pipe`，它只占用一个文件描述符（`pipe` 要两个），内部是一个 64 位计数器——写入时自动加 1，读取时返回当前值并清零。这样 `EventLoop` 不需要处理具体数据，只需知道‘有任务来了’，性能更高、资源更省。虽然 `pipe` 可移植性更好，但在 Linux 服务器场景下，`eventfd` 是更优选择。”

> 🔍 **延伸**：muduo 作者陈硕在《Linux 多线程服务端编程》中明确指出：“`eventfd` 比 `pipe` 快 20% 左右”。

---

## 二、`epoll` vs `select` / `poll`：为什么现代网络库都用 `epoll`？

### ❓ 问题：  
> “`select`/`poll` 也能做 I/O 多路复用，为什么不用它们？”

### ✅ 回答要点：
| 问题 | `select` / `poll` | `epoll` |
|------|------------------|--------|
| **时间复杂度** | O(n)：每次都要遍历所有 fd | O(1)：只返回就绪的 fd |
| **fd 数量限制** | `select` 默认 1024（`FD_SETSIZE`） | 仅受系统限制（数十万） |
| **内核/用户态拷贝** | 每次调用都要传递整个 fd_set | 通过 `epoll_ctl` 注册一次，后续复用 |
| **触发模式** | 仅水平触发（LT） | 支持 LT + 边缘触发（ET） |

### 🗣️ 面试口语化回答：
> “`select` 和 `poll` 的核心问题是**性能随连接数线性下降**——即使只有 1 个连接活跃，也要遍历全部 fd。而 `epoll` 通过内核红黑树 + 就绪链表，做到 **O(1) 事件通知**，且支持百万级连接。此外，`epoll` 的 ET 模式能减少不必要的 `epoll_wait` 唤醒，进一步提升效率。因此，高性能服务器（如 Nginx、Redis、muduo）都基于 `epoll`。”

---

## 三、`SO_REUSEADDR` vs `SO_REUSEPORT`：端口重用的区别？

### ❓ 问题：  
> “`SO_REUSEADDR` 允许重启服务，那 `SO_REUSEPORT` 有什么用？”

### ✅ 回答要点：
| 选项 | 作用 | 典型场景 |
|------|------|--------|
| **`SO_REUSEADDR`** | 允许绑定处于 `TIME_WAIT` 的地址 | 单进程服务快速重启 |
| **`SO_REUSEPORT`** | 允许多个**进程/线程**同时监听同一端口 | 多进程负载均衡（如 Nginx master-worker） |

### 🗣️ 面试口语化回答：
> “`SO_REUSEADDR` 解决的是‘服务重启时端口被占用’的问题，它允许新进程绑定还在 `TIME_WAIT` 的地址。而 `SO_REUSEPORT` 更强大——它允许多个进程（或线程）**同时监听同一个 IP:Port**，内核会自动将新连接**负载均衡**到这些监听者。这在多进程模型（如 Nginx）中能彻底避免‘惊群’问题，提升扩展性。”

> ⚠️ 注意：`SO_REUSEPORT` 需要 Linux 3.9+，且多个 socket 必须设置相同的用户 ID。

---

## 四、边缘触发（ET） vs 水平触发（LT）：为什么 muduo 用 ET？

### ❓ 问题：  
> “`epoll` 支持 LT 和 ET，muduo 为什么选择 ET？”

### ✅ 回答要点：
| 模式 | 行为 | 适用场景 |
|------|------|--------|
| **LT（默认）** | 只要 fd 可读/写，每次 `epoll_wait` 都返回 | 编程简单，适合初学者 |
| **ET** | 仅在状态**变化时**通知一次（如从不可读→可读） | 高性能，减少 epoll 唤醒次数 |

### 🗣️ 面试口语化回答：
> “muduo 使用 ET 模式是为了**减少不必要的系统调用**。在 LT 模式下，只要 socket 接收缓冲区有数据，`epoll_wait` 就会一直返回该 fd，即使你没读完。而 ET 只在‘有新数据到达’时通知一次，迫使程序一次性读完所有数据（配合非阻塞 I/O）。这样能显著降低 `epoll_wait` 的调用频率，提升吞吐量。”

> 💡 **关键配套**：ET 必须搭配 **非阻塞 socket + 循环读取直到 `EAGAIN`**，否则会丢事件。

---

## 五、为什么用非阻塞 I/O（NONBLOCK）？

### ❓ 问题：  
> “为什么 socket 要设为非阻塞？”

### ✅ 回答要点：
- **阻塞 I/O 会挂起整个线程**，导致 EventLoop 无法处理其他连接；
- **非阻塞 + epoll** 实现“事件驱动”：只有可读/可写时才操作，100% CPU 利用率；
- **必须处理 `EAGAIN`/`EWOULDBLOCK`**，这是正常现象，不是错误。

### 🗣️ 面试口语化回答：
> “在一个线程处理成千上万个连接的模型中，**任何阻塞操作都会导致整个服务卡住**。所以 socket 必须设为非阻塞。当 `read` 返回 `EAGAIN` 时，说明内核缓冲区空了，我们只需等待下一次 `EPOLLIN` 通知即可。这种‘事件驱动 + 非阻塞 I/O’是高性能网络库的基石。”

---

## 总结：如何应对这类“历史/原理”问题？

1. **不要死记硬背**，理解 **“问题 → 方案 → 权衡”** 的演进逻辑；
2. **用对比表格** 清晰展示差异（面试时可口头描述）；
3. **结合项目**：例如“我在 `re_muduo` 中使用 `eventfd`，因为它比 `pipe` 更高效”；
4. **承认局限**：如果不知道，可以说“我对这块了解不深，但我的理解是……”，展现学习态度。

---

如果你需要，我可以继续补充：
- `accept4` vs `accept` + `fcntl`
- `TCP_NODELAY`（Nagle 算法）的作用
- 为什么 `mmap` / `sendfile` 能实现零拷贝

这些都能帮你构建完整的“Linux 网络编程知识图谱”。祝你面试顺利！